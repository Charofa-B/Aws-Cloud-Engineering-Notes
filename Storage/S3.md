# S3

* Stores objects `(files)` up to `5TB`.
* Object stored with gloabl `unique url` (Universal Namespace)
* Supprts `Object Automatically encrypted` with SSE-S3 (Amazon S3-managed keys) by set `default bucket encryption`.
    * `Decryption occurs automatically upon download`.

<br><br>

## Components
### Bucket
* `Container` for objects.
* `Globally unique name`, but has a region-specific endpoint.
* Defines `access control`, storage charges, and usage reporting.
### Object
* Individual file stored in S3 with `associated metadata`.
* Consists of :
    * `Key` unique `identifier` within a bucket
    * `Value` actual `data`
    * `Metadata` info about the `object` (e.g.,  `content-type`, which helps browsers `render` files `correctly`.)
    * `Version ID` unique version (if versioning enabled)
    * `Sub-resources` e.g., ACLs, lifecycle policies
### Region Specific Storage
* Each `bucket` is `tied` to a specific AWS `Region`.
* Objects `stay` in the selected `Region` `unless` `replicated` or transferred.

<br><br>

## storage classes
### General purpose
* **S3 Standard** For `frequently` accessed data.
* **S3 Intelligent-Tiering** `Moves` objects `automatically` between tiers `based` on `usage`.
* **S3 Express One Zone** `High-performance`, `single-AZ` storage for `short-lived` data.
* **S3 Standard-IA** `Lower-cost`, `infrequent` access, but high `durability`.
  * Store `infrequently accessed` objects while `still needing rapid access` when required.
* **S3 One Zone-IA** `Like IA` but stored in a `single AZ` (lower cost, `lower resilience`).

### Archive
* **S3 Glacier Instant Retrieval** `Low-cost archive`, retrieval in `milliseconds`.
* **S3 Glacier Flexible Retrieval** `Minutes-to-hours retrieval`, `cheaper` than Instant.
* **S3 Glacier Deep Archive** `Lowest cost`, retrieval in `hours`.

### S3 on Outposts
* Brings `S3 storage` `on-premises` with AWS Outposts hardware.

<br><br>

## Redundancy in S3
1. Upload file to S3
2. S3 `Automatically replicates` file across `multiple AZs` within that region (If We Use 1` AZ` then replication `won t work on cross AZs`)

<br><br>

## Multipart upload
Uploade a `single object` in `multiple parts`, enabling efficient, resilient, and `parallelized` uploads:
* **Independent Uploads** Parts can be `uploaded` in `any order`.
* **Fault Tolerance** `Failed parts` can be `retransmitted` without affecting others.
* **Automatic Assembly** Once all parts are `uploaded`, S3 `combines` them into a `single object`.

*You can Pause and Resume Upload Normally*

<br><br>

## Transfer Acceleration
* `Speeds up` transfers of `data` to S3 buckets from clients `distributed globally`.  
* Useful for applications where users `upload` to a `centralized bucket` from `many regions`.  
* Helps `overcome limitations` of `public internet bandwidth/latency` when sending large data `over long distances`.  

### How It Works
1. Client `uploads data` to the `nearest` Amazon `CloudFront` `edge` location.  
2. The `edge location` uses Amazon’s `optimized AWS` backbone `network` `instead` of the `public internet`.  
3. `Data` is then `securely` and `efficiently` `routed` to the `target S3 bucket` in its AWS Region.  

### Transfer Family
* Fully `managed` AWS `service`
* `Transfer files` into and out of Amazon `S3 storage` or `Amazon Elastic File System (EFS)` over the following `protocols`:
    * Secure Shell (`SSH`) File Transfer Protocol (`SFTP`) version 3
    * File Transfer Protocol Secure (`FTPS`)
    * File Transfer Protocol (`FTP`)
    * Applicability Statement 2 (`AS2`)

**No upfront costs; pay only for what you use.**

#### Some Common Use Cases for Transfer Family With EFS:
* Data distribution
* Supply chain
* Content management
* Web serving applications

<br><br>

## Object Locking
* `Prevents` objects from being `deleted` or `overwritten` for a specified `period` of time
* Designed to help meet `compliance` and `regulatory` requirements

### Key Features:

* **Retention Modes**
    * `Governance Mode` Users with `special permissions` can `override` the lock; `otherwise` objects can’t be deleted or overwritten.
    * `Compliance Mode` `No` user can `delete` or `modify` the object until the retention `period expires`.
* **Retention Period** Define how `long` the object `remains locked` (in days or years).
* **Legal Hold** `Prevent` `deletion` indefinitely, until the `legal hold` is explicitly `removed`.

<br><br>

## S3 versioning
`Protects objects` from accidental `overwrites` and `deletes` by `maintaining` multiple object `versions` on same s3 bucket.


### How It Works
* Creates a `new version` whenever an `object is modified or deleted`.
* `Deleted objects` retain a `delete marker`, but `older versions remain`.

### Bucket-Level Setting
* **Enabled** `Retains` all `versions`, including `delete markers`.
* **Suspended** `Stops versioning` for new objects but `retains` `previous versions`.
* **Disabled (default)** `Overwrites` objects `permanently`.

**Each version increases storage usage, leading to higher costs.**

<br><br>

## S3 Lifecycle Management Policies

`Automatically manage objects` over their `lifecycle` to `reduce cost` and improve `efficiency`.  

### Key Concepts
* **Transition Actions** Move `objects` between storage classes based on `age or rules`.
  * Example: Move from **S3 Standard → S3 Standard-IA → S3 Glacier → S3 Glacier Deep Archive**.
* **Expiration Actions** Automatically `delete` objects after a `specified period`.
* **Abort Incomplete Multipart Uploads** `Clean up `parts` of uploads that `never completed` to save storage costs.
* **Filtering Rules** Apply lifecycle rules based on:
  * **Prefix** – Objects with a certain key prefix
  * **Tags** – Objects with specific tags
  * Combination of prefix and tags

<br><br>

## Data Replication
`Automatically copies` objects from `one bucket` to `another`, either within the same region (`Same-Region Replication, SRR`) or across regions (`Cross-Region Replication, CRR`).

### How It Works
* `Enable` `replication` on a `source bucket`.
* `Define` the `destination` bucket and the `replication rules` (prefix, tags).
* Every `new object` (or updated object if versioning is enabled) is automatically `copied` to the `destination bucket`.

<br><br>

## S3 Storage Lens
* `Analytics tool` that gives organization-wide visibility into `S3 usage and activity`. 
* It helps you `optimize` cost, improve performance, and ensure data protection.

<br><br>

## S3 Object Lambda
* Allows you to `transform or process S3 objects on-the-fly` when they are `retrieved`.

How it works 
  1. Configure a S3 `Object Lambda` `Access` `Point`.  
  2. When an `object` is `requested`, the request `triggers` a `Lambda function`.  
  3. The `Lambda function` can `modify`, `filter`, or `transform` the `object` data `before returning` it to the client.  

<br><br>

## Logging Requests
Provides detailed `records` for the `requests` that are `made to a bucket`.

<br><br>

## Pricing

### Pay For Only What You Use
* Gigabytes of objects stored (per month) with `different pricing` for `each Region` and `each storage class`
* PUT, COPY, POST, LIST or lifecycle transition to move data into any Amazon S3 storage class

### No Charge For Data Transferred
* Out to the internet for the first 100 GB per month
* In from the internet
* Between S3 buckets or to any service in the same AWS Region
* Out to CloudFront